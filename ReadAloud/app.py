from openai import OpenAI
import streamlit as st
import librosa
import numpy as np
import soundfile as sf
import tempfile
import os
import hashlib

# =====================
# OpenAI Client
# =====================
client = OpenAI(api_key=os.environ["OPENAI_API_KEY"])

# =====================
# OpenAI TTSï¼ˆ1å›ã ã‘ï¼‰
# =====================
def tts_openai(text, out_path):
    with client.audio.speech.with_streaming_response.create(
        model="gpt-4o-mini-tts",
        voice="alloy",
        input=text
    ) as response:
        response.stream_to_file(out_path)

# =====================
# TTSçµæœã‚’ã‚­ãƒ£ãƒƒã‚·ãƒ¥
# =====================
def text_to_hash(text):
    return hashlib.sha256(text.encode("utf-8")).hexdigest()
@st.cache_data(show_spinner="éŸ³å£°ç”Ÿæˆä¸­...")
def generate_base_audio_safe(text):
    h = text_to_hash(text)
    cache_path = f"/tmp/tts_{h}.wav"

    if os.path.exists(cache_path):
        y, sr = librosa.load(cache_path, sr=22050)
        return y, sr

    try:
        with tempfile.NamedTemporaryFile(suffix=".wav", delete=False) as f:
            tts_openai(text, f.name)
            os.rename(f.name, cache_path)

        y, sr = librosa.load(cache_path, sr=22050)
        return y, sr

    except Exception as e:
        st.error("TTSç”Ÿæˆã«å¤±æ•—ã—ã¾ã—ãŸï¼ˆRateLimitã®å¯èƒ½æ€§ï¼‰")
        raise e

# =====================
# å£°ã‚¿ã‚¤ãƒ—è¨­å®š
# =====================
VOICE_PRESET = {
    "ç”·å£°ä½":  (-4, 0.95),
    "ç”·å£°ä¸­":  (-2, 1.00),
    "ç”·å£°é«˜":  (0, 1.05),
    "å¥³å£°ä½":  (2, 1.05),
    "å¥³å£°ä¸­":  (4, 1.10),
    "å¥³å£°é«˜":  (6, 1.15),
}

# =====================
# ã‚¢ã‚¯ã‚»ãƒ³ãƒˆã‚«ãƒ¼ãƒ–ç”Ÿæˆ
# =====================
def build_pitch_curve(levels, length):
    x = np.linspace(0, 1, len(levels))
    y = np.array(levels)
    xx = np.linspace(0, 1, length)
    return np.interp(xx, x, y)

# =====================
# æ³¢å½¢åŠ å·¥ï¼ˆãƒ­ãƒ¼ã‚«ãƒ«ã®ã¿ï¼‰
# =====================
def apply_accent(y, sr, levels, voice_type):
    base_pitch, stretch = VOICE_PRESET[voice_type]

    # è©±é€Ÿ
    y = librosa.effects.time_stretch(y, rate=stretch)

    # ãƒ”ãƒƒãƒã‚«ãƒ¼ãƒ–
    curve = build_pitch_curve(levels, len(y))
    pitch = base_pitch + (curve - 2) * 2.5

    y_out = np.zeros_like(y)
    frame = 2048
    hop = 512

    for i in range(0, len(y) - frame, hop):
        seg = y[i:i+frame]
        step = int(np.mean(pitch[i:i+frame]))
        seg = librosa.effects.pitch_shift(seg, sr=sr, n_steps=step)
        y_out[i:i+frame] += seg

    return y_out

# =====================
# Streamlit UI
# =====================
st.title("æ—¥æœ¬èªèª­ã¿ä¸Šã’ï¼ˆRateLimitå®Œå…¨å›é¿ç‰ˆï¼‰")

text = st.text_area(
    "èª­ã¿ä¸Šã’ãƒ†ã‚­ã‚¹ãƒˆ",
    "æ˜¨æ—¥ç§ãŒå…¬åœ’ã§è¦‹ãŸç™½ã„çŠ¬ã¯ã¨ã¦ã‚‚å…ƒæ°—ã§ã—ãŸã€‚"
)

voice_type = st.selectbox(
    "å£°ã‚¿ã‚¤ãƒ—",
    list(VOICE_PRESET.keys())
)

st.divider()

# ---- ã‚¢ã‚¯ã‚»ãƒ³ãƒˆUI ----
st.subheader("ã‚¢ã‚¯ã‚»ãƒ³ãƒˆï¼ˆãƒ¢ãƒ¼ãƒ©æƒ³å®šãƒ»ç›¸å¯¾ï¼‰")

chars = list(text)
levels = []

cols = st.columns(len(chars))
for i, ch in enumerate(chars):
    with cols[i]:
        st.markdown(f"<div style='text-align:center'>{ch}</div>", unsafe_allow_html=True)
        lv = st.radio(
            label=f"accent_{i}",
            options=[0,1,2,3,4],
            index=2,
            key=f"r_{i}",
            label_visibility="collapsed"
        )
        levels.append(lv)

st.divider()

# ---- ä¸Šä¸‹ã«ç”Ÿæˆãƒœã‚¿ãƒ³ ----
if st.button("ğŸ”Š éŸ³å£°ç”Ÿæˆï¼ˆTTSï¼‰"):
    y_base, sr = generate_base_audio_safe(text)
    st.session_state["base_audio"] = (y_base, sr)

if "base_audio" in st.session_state:
    y_base, sr = st.session_state["base_audio"]

    y_out = apply_accent(y_base, sr, levels, voice_type)
    y_out /= np.max(np.abs(y_out) + 1e-9)

    with tempfile.NamedTemporaryFile(suffix=".wav", delete=False) as f:
        sf.write(f.name, y_out, sr)
        st.audio(f.name)
        st.download_button(
            "â¬‡ wavãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰",
            open(f.name, "rb"),
            file_name="accent_voice.wav"
        )
