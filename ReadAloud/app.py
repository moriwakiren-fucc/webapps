from openai import OpenAI
import streamlit as st
from gtts import gTTS
import librosa
import numpy as np
import soundfile as sf
import tempfile
import os
import re

# =====================
# OpenAI client
# =====================
client = OpenAI(api_key=os.environ["OPENAI_API_KEY"])


# =====================
# èª­ã¿ä¸Šã’å¯èƒ½åˆ¤å®š
# =====================
def is_speakable(ch):
    return bool(re.search(r"[ã-ã‚“ã‚¡-ãƒ³ä¸€-é¾¯]", ch))


# =====================
# AIãµã‚ŠãŒãªå–å¾—â†’ãƒ¢ãƒ¼ãƒ©åˆ†è§£
# =====================
def get_furigana(text):
    res = client.responses.create(
        model="gpt-4.1-mini",
        input=(
            "æ¬¡ã®æ—¥æœ¬èªã®æ–‡ç« ã®æœ€ã‚‚ä¸€èˆ¬çš„ãªèª­ã¿æ–¹ã‚’ã²ã‚‰ãŒãªã«å¤‰æ›ã—ã¦ã€"
            "ãŸã ã—ã€è³ªå•ã®å¾©å”±ãªã©ã€èª­ã¿æ–¹ä»¥å¤–ã®ã“ã¨ã¯ä½•ã‚‚è¨€ã‚ãªã„ã§ãã ã•ã„ã€‚\n\n"
            f"{text}"
        )
    )
    return res.output_text.strip()

def get_mora_text(text):
    out_text = get_furigana(text)
    pattern = r'[ã-ã‚“ãƒ¼][ã‚ƒã‚…ã‚‡ããƒã…ã‡ã‰]?'

    moras = re.findall(pattern, out_text)
    moras_joined = "|".join(moras)
    return moras_joined

# =====================
# ãƒ¢ãƒ¼ãƒ©å†…ã‚¢ã‚¯ã‚»ãƒ³ãƒˆã‚«ãƒ¼ãƒ–
# =====================
def build_pitch_curve(level, length, max_shift=4):
    """
    level: 0ã€œ4
    ä¸­å¤®ãŒæœ€å¤§ã«ãªã‚‹å±±å‹ã‚«ãƒ¼ãƒ–
    """
    target = (level - 2) / 2 * max_shift
    x = np.linspace(-1, 1, length)
    curve = (1 - x**2) * target
    return curve


# =====================
# ãƒ¢ãƒ¼ãƒ©éŸ³å£°ç”Ÿæˆ
# =====================
def synth_mora(mora, accent_level, voice_type, sr=22050):
    if not is_speakable(mora):
        return np.zeros(int(sr * 0.12)), sr

    with tempfile.NamedTemporaryFile(suffix=".mp3", delete=False) as f:
        gTTS(text=mora, lang="ja").save(f.name)
        y, sr = librosa.load(f.name, sr=None)

    # å£°ã‚¿ã‚¤ãƒ—è¨­å®š
    if voice_type == "ç”·å£°ä½":
        base_pitch = -4
        stretch = 0.95
    elif voice_type == "ç”·å£°ä¸­":
        base_pitch = -2
        stretch = 1.0
    elif voice_type == "ç”·å£°é«˜":
        base_pitch = 0
        stretch = 1.05
    elif voice_type == "å¥³å£°ä½":
        base_pitch = 2
        stretch = 1.05
    elif voice_type == "å¥³å£°ä¸­":
        base_pitch = 4
        stretch = 1.1
    else:
        base_pitch = 6
        stretch = 1.15

    y = librosa.effects.time_stretch(y, rate=stretch)

    curve = build_pitch_curve(accent_level, len(y))

    frame = 1024
    hop = 256
    out = np.zeros_like(y)

    for i in range(0, len(y) - frame, hop):
        shift = base_pitch + curve[i]
        out[i:i+frame] += librosa.effects.pitch_shift(
            y[i:i+frame],
            sr=sr,
            n_steps=shift,
            n_fft = frame
        )

    return out, sr


# =====================
# Streamlit UI
# =====================
st.title("æ—¥æœ¬èªèª­ã¿ä¸Šã’ï¼ˆãƒ¢ãƒ¼ãƒ© Ã— æ»‘ã‚‰ã‹ã‚¢ã‚¯ã‚»ãƒ³ãƒˆï¼‰")

input_text = st.text_input(
    "èª­ã¿ä¸Šã’ãƒ†ã‚­ã‚¹ãƒˆ",
    "ä»Šæ—¥ç§ãŒå…¬åœ’ã§è¦‹ãŸã€èµ¤ã„å¸½å­ã‚’è¢«ã£ã¦å…ƒæ°—ã«èµ°ã‚Šå›ã£ã¦ã„ãŸç™½ã„çŠ¬ã®é£¼ã„ä¸»ã¯ã€ç§ã®çˆ¶ã®å¤ã„å‹äººã§ã—ãŸã€‚"
)

voice_type = st.selectbox(
    "å£°ã‚¿ã‚¤ãƒ—",
    ["ç”·å£°ä½", "ç”·å£°ä¸­", "ç”·å£°é«˜", "å¥³å£°ä½", "å¥³å£°ä¸­", "å¥³å£°é«˜"]
)

if st.button("â‘  ãƒ¢ãƒ¼ãƒ©åˆ†è§£"):
    st.session_state["mora_text"] = get_mora_text(input_text)

if "mora_text" in st.session_state:
    moras = st.session_state["mora_text"].split("|")

    st.subheader("ãƒ¢ãƒ¼ãƒ©ã‚¢ã‚¯ã‚»ãƒ³ãƒˆï¼ˆä¸Šã»ã©é«˜ï¼‰")

    cols = st.columns(len(moras))
    accent_levels = []

    for i, (col, mora) in enumerate(zip(cols, moras)):
        with col:
            st.markdown(
                f"<div style='text-align:center;font-weight:bold'>{mora}</div>",
                unsafe_allow_html=True
            )
            level = st.radio(
                "ã‚¢ã‚¯ã‚»ãƒ³ãƒˆé¸æŠ",
                [0, 1, 2, 3, 4],
                index=2,
                key=f"a_{i}",
                label_visibility="collapsed",
                format_func=lambda _: ""
            )
            accent_levels.append(level)

    st.markdown("---")

    if st.button("â‘¡ éŸ³å£°ç”Ÿæˆ"):
        st.success("ã“ã“ã¾ã§ã¯OK", icon="ğŸ‘")
        audio = []

        for mora, level in zip(moras, accent_levels):
            y, sr = synth_mora(mora, level, voice_type)
            audio.append(y)

        y_all = np.concatenate(audio)
        y_all /= np.max(np.abs(y_all))

        with tempfile.NamedTemporaryFile(suffix=".wav", delete=False) as f:
            sf.write(f.name, y_all, sr)
            st.audio(f.name)
            st.download_button(
                "éŸ³å£°ã‚’ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ï¼ˆwavï¼‰",
                open(f.name, "rb"),
                file_name="accent_voice.wav"
            )
